# 💳 Fraud Detection System
Python 기반 머신러닝과 Ensemble, SHAP 해석을 결합해 성능과 설명 가능성을 동시에 고려한 금융 사기 탐지 모델을 구현한 프로젝트

## 프로젝트 기간
2026.01.11 ~ 2026.01.16 (6 days)

## 🛠️ 기술 스택
- Python

## 📂 Project Structure
```
FraudDetectionSystem/
│
├── src/
│   ├── data/
│   │   ├── load_data.py               # Google Drive 데이터 다운로드
│   │   └── preprocess.py              # Log 변환 + Min-Max Scaling
│   │
│   ├── features/
│   │   ├── pls_vip.py                 # PLS Regression + VIP 계산
│   │   └── feature_selection.py       # Pearson~MI~VIP 통합 변수 선정
│   │
│   ├── models/
│   │   ├── train_lgbm.py              # LightGBM 단일 모델 학습
│   │   └── voting_ensemble.py         # Soft Voting Ensemble
│   │
│   ├── evaluation/
│   │   ├── metrics.py                 # ROC-AUC 평가
│   │   └── fp_fn_analysis.py          # FP / FN 인덱스 및 비교 분석
│   │
│   ├── explainability/
│   │   ├── shap_global.py             # SHAP Global 해석 (summary plot)
│   │   ├── shap_importance.py        # SHAP importance 해석 (FP / FN 사례)
│   │   └── shap_local.py              # SHAP Local 해석 (FP / FN 사례)
│   │
│   └── imports/                                # 패키지 형상관리
│
├── figures/
│   ├── readme.md
│   ├── result-figure-1-PLS-Biplot-2-Components.png
│   ├── result-figure-2-PLS-Biplot-3-Components.png
│   ├── result-figure-3-VIP-Scores.png
│   ├── result-figure-4-Feature-Selection.png
│   ├── result-figure-5-global.png
│   ├── result-figure-6-local.png
│   └── result-figure-7-importance.png
└── README.md
```

---

# 1. 문제 정의
## 1.1. 프로젝트 시나리오 개요
신용카드 거래는 신용을 기반으로 이루어지는 대표적인 금융 거래로, 거래의 신뢰성과 안전성은 카드사와 고객 모두에게 매우 중요한 요소이다. 특히 카드 소유주 본인이 아닌 제 3자에 의해 이루어지는 부정거래(Fraud Transaction)는 고객의 금전적 손실뿐 아니라 카드사에 대한 신뢰 저하로 이어질 수 있다.

카드사 입장에서는 정상 거래가 압도적으로 많기 때문에 단순 정확도(Accuracy)에 기반한 판단만으로는 부정 거래를 효과적으로 탐지하기가 어렵다. 실제로 소수의 부정 거래를 놓칠 경우 고객 피해로 직결되므로, 부정 거래를 얼마나 정확히 탐지할 수 있는지가 핵심 과제이다.

이에 본 프로젝트에서는 과거 신용카드 거래 정보를 활용하여, 각 거래가 정상 거래인지 부정 거래인지를 인공지능 모델로 판단하는 시스템을 구축하고자 한다. 이를 통해 향후 발생하는 모든 카드 결제 거래에 대해 실시간 이상 거래 탐지 및 사전 경고가 가능한 서비스 구축의 기초 단계를 마련하는 것을 목표로 한다. 특히 부정 거래 비율이 매우 낮은 특성을 고려하여, 단순 정확도가 아닌 Precision-Recall 곡선 기반 지표(AUPRC)를 중심으로 모델 성능을 평가하고, 실제 금융 서비스 환경에 적합한 이상 거래 탐지 모델을 구현하는 것을 핵심 문제로 정의하였다.

</br>

# 2. 데이터 설명
## 2.1. 데이터 세트 개요
본 프로젝트에서는 신용카드 부정 거래 탐지를 위한 공개 데이터 세트인 Credit Card Fraud Detection 을 사용하였다. 해당 데이터는 실제 유럽 카드 이용자의 거래 기록을 기반으로 구성된 데이터로, 금융 거래 환경에서 발생하는 이상 거래를 분석하기에 적합한 구조를 가진다.
- 데이터 세트명: Credit Card Fraud Detection
- 데이터 출처: Kaggle – Credit Card Fraud Detection (https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)
- 데이터 수집 시점: 2013년 9월
- 총 거래 건수: 284,807건
- 총 컬럼 수: 31개

## 2.2. 데이터 구성 및 변수 설명
데이터는 개별 신용카드 거래 단위로 구성되어 있으며, 각 거래에 대해 총 31개의 수치형 변수가 제공된다. 이 중 거래 시간과 거래 금액을 제외한 대부분의 변수는 개인정보 보호 및 보안상의 이유로 PCA(Principal Component Analysis)를 통해 변환된 값이다.

|변수명|설명|
|------|----|
|`Time`|	첫 번째 거래 발생 시점을 기준으로 경과한 시간(초 단위)
|`V1` ~ `V28`|	원본 거래 정보를 PCA로 차원 축소한 수치형 변수
|`Amount`|	해당 거래의 결제 금액
|`Class`|	이상 거래 여부 (0: 정상 거래, 1: 부정 거래)

`Time` 변수는 절대적인 거래 시각이 아닌, 데이터 내 첫 거래 이후 경과 시간을 나타내며 거래 간 시간 간격 분석에 활용될 수 있다.
`Amount` 변수는 거래 금액 정보를 포함하고 있어, 부정 거래 탐지 시 거래 규모에 따른 위험도 판단이나 비용 민감 학습(cost-sensitive learning) 에 활용 가능하다.

## 2.3. 데이터 특성 및 분석 시 고려사항
해당 데이터 세트의 가장 큰 특징은 심각한 클래스 불균형(Class Imbalance) 이다. 전체 284,807건의 거래 중 부정 거래(Class = 1)는 492건에 불과하며, 이는 전체 거래의 약 0.172% 수준이다. 이로 인해 정상 거래(Class = 0)가 압도적으로 많은 구조를 가진다.

이러한 데이터 특성상 단순 정확도(Accuracy)를 모델 성능 지표로 사용할 경우, 부정 거래를 거의 탐지하지 못하더라도 높은 정확도가 나타날 수 있다. 따라서 본 프로젝트에서는 부정 거래 탐지 성능을 보다 정밀하게 평가하기 위해 Precision-Recall 기반 평가 지표(`ROC_AUC`)를 중심으로 모델을 분석한다.

또한 PCA로 변환된 변수들(V1~V28)은 원본 의미를 직접적으로 해석하기 어렵기 때문에, 본 프로젝트에서는 변수 중요도 분석 및 설명가능한 AI(XAI)를 이용하여 각 변수가 이상 거래 판별에 미치는 상대적 영향을 분석한다.

</br>

# 3. 탐색적 자료 분석(EDA) 및 변수 선정(Feature Selection)
## 3.1. 데이터 전처리
데이터의 품질을 점검하고, 변수 간 스케일 차이로 인한 왜곡을 최소화하기 위해 데이터 전처리 과정을 수행하였다.

```
(1) 결측치 분석(Missing Data check) -> (2) 이상치 점검(Outlier Check) -> (3) 데이터 스케일링(Data Scaling)
```

먼저 전체 데이터에 대해 결측치(Missing Data)여부를 확인한 결과, 모든 변수에서 결측치는 존재하지 않았다. 그 다음 이상치 점검의 경우, 데이터의 특성에 의하여 처리하지 않았다. 마지막으로 데이터 스케일링의 경우 `Log Transform`과 `Min-Max Scaling`을 진행하였다.
이러한 전처리 과정을 통해 변수 간 상대적 영향력을 균형 있게 조정하였으며, 특정 변수의 크기 차이가 모델 학습에 과도한 영향을 미치는 문제를 최소화 하였다.

## 3.2. 데이터 시각화 및 분석
본 절에는 전처리된 데이터를 바탕으로 PLS(Partial Least Squares) 기반 시각화 결과를 통해 정상 거래와 이상 거래의 분포 특성과 주요 변수의 기여도를 분석하였다. 특히 차원 축소 이후의 공간에서 클래스 간 분리 가능성과 변수 간 관계를 직관적으로 파악하는 데 목적이 있다.

### 3.2.1. PLS Biplot 분석
<div align="center">
 <img src="/figures/result-figure-1-PLS-Biplot-2-Components.png" width="400"/> <img src="/figures/result-figure-2-PLS-Biplot-3-Components.png" width="400"/>
</div>

2-Components로 분석 결과 정상 거래와 이상 거래는 명확히 분리되기보다는 일부 중첩된 구조를 가진다. 벡터들을 분석하면, `V17`, `V14`, `V12`의 변수가 정상거래에 큰 설명력을 띔을 확인할 수 있다. 반면, 3-Components로 분석한 결과 정상 거래와 이상 거래가 약간 분리됨을 보였다. 특히 `V17` 방향(위의 그림)으로 포맷팅을 하고 확인해 본 결과, 이상 거래 변수들끼리 뭉쳐있으나, 일부 중첩된 부분이 존재되었다. 따라서 변수를 선별하여(변수 축소) 모델링을 진행하는 방법을 선택하였다.

</br>
<div align="center">
 <img src="/figures/result-figure-3-VIP-Scores.png" width="500"/>
 </div>

위의 PLS 분석 결과 기반의 VIP Scores를 산출해 보았다. 기준을 VIP >= 1.21로 둔 다음 분석한 결과 `V17`, `V14`, `V12`, `V10`, `V3`, `V16`, `V7`}이 높은 상관성을 띄었다. 분석 전, 주요 변수라고 생각했던 `Amount`와 `Time`의 경우 낮은 점수를 띄고 있었다. 현재는 데이터가 보안상의 이유로 더 엄밀하게 접근 할 수 없으나, 훗날 데이터가 PCA 차원축소가 되어있지 않다면, 더 다양한 분석 기법을 활용하여 점검할 수 있을 것으로 사료된다.

</br>

## 3.3. 변수 선정
본 절에서는 여러 기법에서 반복적으로 중요하게 나타난 변수를 선택하여 평균 Rank 기반의 누적평가를 통해 상위 10개의 변수를 선별하려고 한다(Consensus 기반). 사용될 방법론은 아래와 같다.

|그룹	|기법	|중요도 기준|
|-|-|-|
|선형 관계|	Pearson	|단변량 선형 상관|
|        |	Ridge	|다변량 선형 + L2 패널티|
|        |	Lasso	|다변량 선형 + 변수 선택|
|        |	Elastic Net	|Ridge + Lasso|
|비선형 관계|	Spearman	|단변량 순위 상관|
|          |	MI	|일반적 비선형 의존성|
|잠재공간 기반|	PLS-VIP	|X–Y 공분산 기여도|

<div align="center">
 <img src="/figures/result-figure-4-Feature-Selection.png" width="500"/>
</div>

분석 결과 상위 10개의 변수는 `V17`, `V14`, `V12`, `V10`, `V7`, `V16`, `V3`, `V11`, `V4`, `V9`이다. 가장 높은 Rank를 차지한 `V17`의 경우 모든 분석 결과에서 높은 관계를 나타내었다. 눈에 띄는 점은 5번째 Rank인 `V7`의 경우 모든 변수 중에서 `Ridge`의 결과가 가장 높았다. 이는 Ridge가 공동 기여 변수를 높게 평가하기 때문이다. `V7`은 단독으로는 약한 변수일 지라도, 다른 변수와 함께 있을 때, 예측에 크게 기여한다는 의미이다.

</br>

# 4. 모델링 전략 및 성능 평가
## 4.1. 모델링 전략 개요
본 프로젝트에서는 이상 거래 탐지 성능을 극대화하기 위해 앙상블 모델링(Ensemble Modeling) 전략을 적용하였다. 단일 모델은 특정 데이터 패턴에 강점을 가지는 반면, 데이터 분포나 오류 유형에 따라 성능이 제한될 수 있다는 한계가 있다. 이에 따라 서로 다른 학습 특성을 가진 여러 모델을 결합함으로써 일반화 성능을 향상시키고 예측 안정성을 확보하고자 하였다. 이를 위해 VotingClassifier 기반의 앙상블 모델을 구성하였으며, 각 모델의 예측 결과를 종합하여 최종 예측을 수행하였다.

## 4.2. 앙상블 모델 구성
앙상블 모델은 다음과 같이 서로 다른 특성을 가진 4개의 분류 모델로 구성하였다.

- `LogisticRegression` : 선형 결정 경계를 기반으로 한 기본 모델로, 해석 가능성과 안정적인 기준 성능 제공
- `RandomForestClassifier` : 다수의 결정트리를 활용하여 비선형 관계를 학습할 수 있는 앙상블 트리 기반 모델
- `LGBMClassifier` : 대규모 데이터와 복잡한 패턴에 강점을 가지는 Gradient Boosting 기반 모델
- `XGBClassifier` : 부정 거래 탐지 분야에서 우수한 성능을 보이는 대표적인 부스팅 모델

각 모델은 동일한 전처리 데이터를 기반으로 학습되었으며, `VotingClassifier`를 통해 개별 모델의 예측 결과를 결합하여 최종 이상 거래 여부를 판단하였다.

## 4.3. 모델 학습 및 검증 절차

모델링 과정은 `예측 → 검증 → 사후검증`의 단계로 수행하였다.
먼저 학습된 모델을 통해 이상 거래 여부를 예측하고, 검증 데이터에 대해 성능을 평가하였다. 이후 모델 해석 단계에서는 변수 중요도 및 기여도를 분석하여, 앞서 수행한 변수선정 결과와의 일관성을 확인하였다.

이상 거래 데이터의 극심한 불균형을 고려하여, 모델 성능 평가는 단순 정확도 대신 ROC-AUC 지표를 중심으로 수행하였다.

## 4.4. 성능 비교 분석(Comparison Analysis)
앙상블 모델과 단일 모델 간 성능 비교 결과는 다음과 같다.

- 앙상블 모델 (VotingClassifier): ROC-AUC Score: 0.9807
- 단일 모델 (LGBMClassifier): ROC-AUC Score: 0.9591

비교 결과, 앙상블 모델은 단일 LGBM 모델 대비 유의미한 성능 향상을 보였으며, 이는 각 모델이 학습한 서로 다른 패턴 정보를 결합함으로써 이상 거래를 보다 정밀하게 탐지할 수 있었기 때문으로 판단된다. 특히 단일 모델에서 발생할 수 있는 예측 편향을 완화하고, 전반적인 분류 안정성을 개선한 점에서 앙상블 전략의 효과를 확인할 수 있었다.

## 4.5. 파인 튜닝(Fine Tunning) 및 향후 개선 방향
현재 구축한 앙상블 모델은 초기 목표 성능이었던 ROC-AUC 95%를 크게 상회하는 약 98% 수준의 성능을 달성하였다. 이는 모델 구조 및 변수선정 전략이 이상 거래 탐지 문제에 적합하게 설계되었음을 의미한다.

향후 모델 고도화 단계에서는 개별 모델에 대한 하이퍼파라미터 튜닝을 더욱 정교하게 수행하고, 앙상블 내 모델 가중치 조정 및 오류 유형(FP/FN)별 성능 분석을 통해 ROC-AUC 99% 수준의 성능 달성을 목표로 추가적인 개선을 진행할 예정이다.

</br>

# 5. SHAP 기반 XAI를 활용한 분석
본 절에서는 앙상블 모델의 예측 결과를 바탕으로, 변수 중요도 분석 및 SHAP 값을 활용한 모델 해석, 그리고 오탐(False Positive)과 미탐(False Negative) 관점에서의 오류 분석을 수행하였다. 이를 통해 단순 성능 수치가 아닌, 모델이 어떻게 판단을 내리는지에 대한 해석 가능성을 확보하고자 하였다.

## 5.1. Global Interpretation

<div align="center">
 <img src="/figures/result-figure-5-global.png" width="500"/>
</div>

SHAP(SHapley Additive exPlanations) 분석 결과를 Global하게 시각화 하기 위해 Beeswarm Plot을 나타내 보았다. 이는 해당 변수의 값이 클 때 예측값을 올리는지 또는 내리는지를 분석하는 값이다. 위 결과를 보면, 대체적으로 밀집되어있는 것이 없으므로 모델은 위 변수들의 변화에 대해 예민하게 반응하였음을 뜻한다.

`V4`의 경우 Feature Value가 높은 값들이 오른쪽에 몰려있다. 이를 보았을 때 `V4`의 값이 클 수록 모델의 예측치를 높인다고 할 수 있다. 반면, `V10`, `V14`의 경우 Feature Value가 낮은 값들이 오른쪽에 몰려있다. 이들의 값이 작을 수록 예측치를 높인다는 의미이다.

여기서 주목할 만한 데이터는 `V17`이다. 앞선 Feature Selection 단계에서 가장 RANK가 높은 변수였기 때문이다. SHAP 분석 결과, `V17`의 값들의 분포는 대체적으로 0큼을 알 수 있다. 하지만, 값들이 섞여 있고, SHAP value가 4-6 일 때는 Feature value가 낮은 값들이 분포하고 있고 SHAP value가 1-4일 때에는 Feature value가 높은 값들이 분포하고 있다. 이를 보았을 때 V17의 값은 모델 내부에서 값이 작을 수록 예측력이 좋다고 해석할 수 있으며, 가장 영향력을 높게 미친 변수라고 판단할 수 있다.

## 5.2. Local Interpretation
<div align="center">
 <img src="/figures/result-figure-6-local.png" width="600"/>
</div>

위 그림은 SHAP local force plot이다. Base value는 약 -7로, 전체 데이터 기준 평균적인 모델의 출력값임을 뜻한다. 최종 예측값은 f(x)=-11.82로, 따라서 해당 샘플 값(local값)은 평균적인 경우보다 더 음성(negative)방향으로 강하게 예측된 값이다.

본 local 사례는 다수의 주요 변수들이(`V12`, `V20`, `V18` 등) 일관되게 음의 방향으로 작용하며 예측값을 크게 하락시키는 구조를 보였다. 예측값은 decision boundary로부터 충분히 멀리 위치해 있어, 모델이 불확실성 없이 Negative 클래스로 분류한 사례로 해석된다. 이는 FP(False Positive, 모델이 Positive로 잘못 예측한 경우) 또는 FN(False Negative, 모델이 Negative로 잘못 예측한 경우)과 같은 경계 오류보다는, 모델이 학습한 전형적인 Negative 패턴을 충실히 반영한 TN(True Negative) 사례에 해당할 가능성이 높으므로, 본 프로젝트에서 개발한 앙상블 모델은 XAI 기법에 의하여 정상에 가깝다고 설명할 수 있다.

## 5.3. FP / FN 관점에서의 SHAP 기반 오류 특성 종합 분석
<div align="center">
 <img src="/figures/result-figure-7-importance.png" width="600"/>
</div>

앞선 Global 및 Local SHAP 분석을 바탕으로, 본 절에서는 오탐(False Positive)과 미탐(False Negative) 사례에서의 변수 기여도를 비교 분석하여 모델 오류의 구조적 특성을 종합적으로 살펴보았다.

FP와 FN 샘플을 대상으로 평균 절대 SHAP 값을 비교한 결과, 두 오류 유형은 상이한 특성을 보였다. FP의 경우 `V17`이 다른 변수들에 비해 압도적으로 높은 SHAP 값을 보이며, 특정 핵심 변수가 과도하게 Positive 방향으로 작용할 때 오탐이 발생하는 경향이 확인되었다. 이는 Global 해석에서 중요도가 높았던 변수가 개별 예측에서는 오히려 오류 요인으로 작용할 수 있음을 시사한다.

반면 FN의 경우 `V10`, `V4`, `V12`, `V14`, `V16` 등 다수 변수들이 비교적 고르게 분포하며 기여하는 양상을 보였다. 이는 단일 변수의 극단적인 값보다는 여러 변수의 누적된 영향으로 인해 실제 Positive 샘플이 Negative로 분류되는 구조임을 의미한다.

이러한 결과는 Local Interpretation에서 확인된 TN 사례와도 일관된다. 해당 사례는 다수의 주요 변수가 강하게 음의 방향으로 작용하며 decision boundary로부터 충분히 떨어진 예측값을 형성하였으며, 이는 FN과 같은 경계 오류가 아닌 모델이 학습한 전형적인 Negative 패턴에 기반한 판단임을 뒷받침한다.

종합적으로, SHAP 기반 XAI 분석을 통해 본 앙상블 모델은 단순한 예측 성능을 넘어, 오류 발생의 원인과 구조를 명확히 설명할 수 있음을 확인하였다. 이는 모델의 신뢰성과 해석 가능성을 동시에 확보했다는 점에서 본 연구의 중요한 의의라 할 수 있다.

</br>

# 6. 결과 및 고찰
본 프로젝트에서는 극심한 클래스 불균형을 가진 신용카드 거래 데이터를 대상으로, 이상 거래 탐지를 위한 앙상블 기반 분류 모델을 구축하였다. VotingClassifier를 활용한 앙상블 모델은 단일 모델 대비 우수한 성능을 보였으며, ROC-AUC 기준 약 0.98 수준의 탐지 성능을 달성함으로써 부정 거래 탐지 문제에서 높은 분류 성능과 안정성을 확보하였다.

또한 SHAP 기반 XAI 분석을 통해 모델의 의사결정 구조를 해석하였다. Global 분석 결과 V17, V14, V12 등의 변수가 이상 거래 판별에 핵심적인 역할을 수행함을 확인하였으며, 이는 변수 선정 단계에서 도출된 결과와도 일관되었다. Local 분석에서는 개별 거래 단위에서 다수 변수의 누적된 기여가 예측 결과를 형성하는 과정을 확인함으로써, 모델이 단일 변수에 의존하지 않고 패턴 기반으로 판단하고 있음을 검증하였다. 더 나아가 FP와 FN 오류 유형별 SHAP 분석을 통해, 오탐은 특정 핵심 변수의 과도한 반응으로 발생하는 반면, 미탐은 다수 변수의 누적 효과에 의해 발생하는 구조적 차이를 확인하였다.

이러한 분석 결과는 본 모델이 단순히 높은 예측 성능을 달성하는 데 그치지 않고, 예측 결과의 근거와 오류 발생 원인까지 설명 가능한 이상 거래 탐지 모델임을 보여준다. 나아가 실무 적용 관점에서 본 모델은 실시간 카드 결제 환경에서 사전 경고 시스템으로 활용 가능하며, SHAP 기반 설명을 통해 개별 거래가 이상으로 판단된 이유를 함께 제공함으로써 금융기관 내부 모니터링 담당자의 의사결정을 효과적으로 지원할 수 있다. 또한 FP·FN 구조 분석 결과를 바탕으로 임계값 조정이나 비용 민감 정책을 적용할 경우, 불필요한 오탐으로 인한 고객 불편을 줄이는 동시에 고객 피해 최소화와 운영 효율성 개선을 동시에 달성할 수 있을 것으로 기대된다.
